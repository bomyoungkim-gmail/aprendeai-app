time="2025-12-23T18:28:08-03:00" level=warning msg="The \"OPENAI_API_KEY\" variable is not set. Defaulting to a blank string."
time="2025-12-23T18:28:08-03:00" level=warning msg="The \"ANTHROPIC_API_KEY\" variable is not set. Defaulting to a blank string."
time="2025-12-23T18:28:08-03:00" level=warning msg="The \"GOOGLE_API_KEY\" variable is not set. Defaulting to a blank string."
#1 [internal] load local bake definitions
#1 reading from stdin 3.37kB done
#1 DONE 0.0s

#2 [content_processor internal] load build definition from content_processor.Dockerfile
#2 transferring dockerfile: 233B done
#2 DONE 0.0s

#3 [frontend internal] load build definition from frontend.Dockerfile
#3 transferring dockerfile: 190B done
#3 DONE 0.0s

#4 [news_ingestor internal] load build definition from news_ingestor.Dockerfile
#4 transferring dockerfile: 221B done
#4 DONE 0.0s

#5 [arxiv_ingestor internal] load build definition from arxiv_ingestor.Dockerfile
#5 transferring dockerfile: 224B done
#5 DONE 0.0s

#6 [api internal] load build definition from api.Dockerfile
#6 transferring dockerfile: 1.63kB done
#6 DONE 0.0s

#7 [extraction_worker internal] load build definition from extraction_worker.Dockerfile
#7 transferring dockerfile: 560B done
#7 DONE 0.0s

#8 [ai internal] load build definition from Dockerfile
#8 transferring dockerfile: 799B done
#8 DONE 0.0s

#9 [auth] library/node:pull token for registry-1.docker.io
#9 DONE 0.0s

#10 [extraction_worker internal] load metadata for docker.io/library/node:20-alpine
#10 ...

#11 [ai internal] load metadata for docker.io/library/python:3.11-slim
#11 DONE 0.6s

#12 [ai internal] load .dockerignore
#12 transferring context: 2B done
#12 DONE 0.0s

#13 [ai internal] load build context
#13 transferring context: 14.53kB 0.0s done
#13 DONE 0.0s

#14 [ai 1/6] FROM docker.io/library/python:3.11-slim@sha256:158caf0e080e2cd74ef2879ed3c4e697792ee65251c8208b7afb56683c32ea6c
#14 resolve docker.io/library/python:3.11-slim@sha256:158caf0e080e2cd74ef2879ed3c4e697792ee65251c8208b7afb56683c32ea6c 0.0s done
#14 DONE 0.0s

#15 [ai 3/6] RUN apt-get update && apt-get install -y   gcc   g++   postgresql-client   && rm -rf /var/lib/apt/lists/*
#15 CACHED

#16 [ai 2/6] WORKDIR /app
#16 CACHED

#17 [ai 4/6] COPY requirements.txt .
#17 CACHED

#18 [ai 5/6] RUN pip install --no-cache-dir -r requirements.txt
#18 ...

#10 [content_processor internal] load metadata for docker.io/library/node:20-alpine
#10 DONE 1.1s

#19 [content_processor internal] load .dockerignore
#19 transferring context: 378B done
#19 DONE 0.0s

#20 [api 1/7] FROM docker.io/library/node:20-alpine@sha256:658d0f63e501824d6c23e06d4bb95c71e7d704537c9d9272f488ac03a370d448
#20 resolve docker.io/library/node:20-alpine@sha256:658d0f63e501824d6c23e06d4bb95c71e7d704537c9d9272f488ac03a370d448 0.0s done
#20 DONE 0.0s

#21 [arxiv_ingestor internal] load build context
#21 transferring context: 3.67kB 0.0s done
#21 DONE 0.0s

#22 [news_ingestor internal] load build context
#22 transferring context: 4.58kB 0.0s done
#22 DONE 0.0s

#23 [arxiv_ingestor 3/5] COPY services/workers/arxiv_ingestor/package*.json ./
#23 CACHED

#24 [arxiv_ingestor 4/5] RUN npm install
#24 CACHED

#25 [arxiv_ingestor 5/5] COPY services/workers/arxiv_ingestor/ .
#25 CACHED

#26 [news_ingestor 2/7] WORKDIR /app
#26 CACHED

#27 [news_ingestor 3/5] COPY services/workers/news_ingestor/package*.json ./
#27 CACHED

#28 [news_ingestor 4/5] RUN npm install
#28 CACHED

#29 [news_ingestor 5/5] COPY services/workers/news_ingestor/ .
#29 CACHED

#30 [content_processor internal] load build context
#30 transferring context: 4.05kB 0.1s done
#30 DONE 0.1s

#26 [content_processor 2/7] WORKDIR /app
#26 CACHED

#31 [content_processor 3/5] COPY services/workers/content_processor/package*.json ./
#31 CACHED

#32 [content_processor 4/5] RUN npm install
#32 CACHED

#33 [content_processor 5/5] COPY services/workers/content_processor/ .
#33 CACHED

#34 [content_processor] exporting to image
#34 exporting layers done
#34 exporting manifest sha256:88167edd86661671f4893927d5b892f9cd62ac9f1881968599fa6eb1b7a641bb done
#34 exporting config sha256:ac855e4c9794ddc13f3a29d72d156e77197e38b11b3c88886e7ee5a823056d64 done
#34 exporting attestation manifest sha256:084529e1d673651ac44c1a867cfbdb90c8c6f9b5748fc6fa3fc7eef62b2e1793 0.0s done
#34 exporting manifest list sha256:f87bf5619a4baf56419840e7eaed78bc763f62d55d9e218a63a443cd04919b43
#34 exporting manifest list sha256:f87bf5619a4baf56419840e7eaed78bc763f62d55d9e218a63a443cd04919b43 0.0s done
#34 naming to docker.io/socrates/content-processor:latest done
#34 unpacking to docker.io/socrates/content-processor:latest 0.0s done
#34 DONE 0.1s

#35 [arxiv_ingestor] exporting to image
#35 exporting layers done
#35 exporting manifest sha256:99660b2f9e80c8f0eda7dffd8bfd788ac6a511217a8396068ae76b2e9b843429 done
#35 exporting config sha256:6cd0da3b8eb153fa6f1c798c23d7d18be35e86d8e288ddd94501a820d5af5042 done
#35 exporting attestation manifest sha256:a28a17f09d4aa5ba447d67f855a37905f8806c28ce46acf98d06cf94776c407c 0.0s done
#35 exporting manifest list sha256:e6c2b1cbfe9b45be5c89702df86d0d88730e1be3ee6fe0755dabce3119590270 0.0s done
#35 naming to docker.io/socrates/arxiv-ingestor:latest done
#35 unpacking to docker.io/socrates/arxiv-ingestor:latest 0.0s done
#35 DONE 0.2s

#36 [news_ingestor] exporting to image
#36 exporting layers done
#36 exporting manifest sha256:176378aa80901dd51b42be73c73bd9b496c83c95049ba87781be602a220aa7ed done
#36 exporting config sha256:66ab3402894169dffbf526c106cd2638c370135c609098c33d9430f92838accb done
#36 exporting attestation manifest sha256:cb04fa721f8ba24f5bb6052d2b82599c30c2543882f4b5c9b68859139bb136e4 0.0s done
#36 exporting manifest list sha256:b5a136292028e11f77906e1b01e9b83912e478e7b3aa92340cc5380655b020db 0.0s done
#36 naming to docker.io/socrates/news-ingestor:latest done
#36 unpacking to docker.io/socrates/news-ingestor:latest 0.0s done
#36 DONE 0.2s

#37 [extraction_worker internal] load build context
#37 ...

#38 [news_ingestor] resolving provenance for metadata file
#38 DONE 0.1s

#39 [arxiv_ingestor] resolving provenance for metadata file
#39 DONE 0.1s

#40 [content_processor] resolving provenance for metadata file
#40 DONE 0.1s

#37 [extraction_worker internal] load build context
#37 ...

#41 [api internal] load build context
#41 transferring context: 1.60MB 1.7s done
#41 DONE 1.8s

#26 [api 2/7] WORKDIR /app
#26 CACHED

#42 [api stage-1 3/9] COPY services/api/package*.json ./
#42 CACHED

#43 [api builder  3/12] RUN apk add --no-cache python3 make g++
#43 CACHED

#44 [api builder  4/12] COPY services/api/package*.json ./
#44 CACHED

#37 [extraction_worker internal] load build context
#37 ...

#18 [ai 5/6] RUN pip install --no-cache-dir -r requirements.txt
#18 1.460 Collecting fastapi==0.109.0 (from -r requirements.txt (line 7))
#18 1.500   Downloading fastapi-0.109.0-py3-none-any.whl.metadata (24 kB)
#18 1.558 Collecting uvicorn==0.27.0 (from uvicorn[standard]==0.27.0->-r requirements.txt (line 8))
#18 1.565   Downloading uvicorn-0.27.0-py3-none-any.whl.metadata (6.4 kB)
#18 1.583 Collecting python-dotenv==1.0.0 (from -r requirements.txt (line 9))
#18 1.589   Downloading python_dotenv-1.0.0-py3-none-any.whl.metadata (21 kB)
#18 1.702 Collecting pydantic==2.5.3 (from -r requirements.txt (line 10))
#18 1.711   Downloading pydantic-2.5.3-py3-none-any.whl.metadata (65 kB)
#18 1.718      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.6/65.6 kB 12.2 MB/s eta 0:00:00
#18 1.827 Collecting langchain==0.1.0 (from -r requirements.txt (line 15))
#18 1.837   Downloading langchain-0.1.0-py3-none-any.whl.metadata (13 kB)
#18 1.914 Collecting langchain-core==0.1.20 (from -r requirements.txt (line 16))
#18 1.922   Downloading langchain_core-0.1.20-py3-none-any.whl.metadata (6.0 kB)
#18 1.961 Collecting langchain-openai==0.0.5 (from -r requirements.txt (line 17))
#18 1.969   Downloading langchain_openai-0.0.5-py3-none-any.whl.metadata (2.5 kB)
#18 2.002 Collecting langchain-anthropic==0.1.0 (from -r requirements.txt (line 18))
#18 2.013   Downloading langchain_anthropic-0.1.0-py3-none-any.whl.metadata (1.8 kB)
#18 2.071 Collecting langchain-google-genai==0.0.7 (from -r requirements.txt (line 19))
#18 2.080   Downloading langchain_google_genai-0.0.7-py3-none-any.whl.metadata (2.9 kB)
#18 2.145 Collecting langgraph==0.0.40 (from -r requirements.txt (line 24))
#18 2.154   Downloading langgraph-0.0.40-py3-none-any.whl.metadata (43 kB)
#18 2.157      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.1/43.1 kB 50.7 MB/s eta 0:00:00
#18 2.176 Collecting aiofiles==24.1.0 (from -r requirements.txt (line 26))
#18 2.184   Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)
#18 2.216 Collecting httpx==0.26.0 (from -r requirements.txt (line 31))
#18 2.222   Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)
#18 2.271 Collecting pytest==7.4.3 (from -r requirements.txt (line 42))
#18 2.280   Downloading pytest-7.4.3-py3-none-any.whl.metadata (7.9 kB)
#18 2.307 Collecting pytest-asyncio==0.21.1 (from -r requirements.txt (line 43))
#18 2.334   Downloading pytest_asyncio-0.21.1-py3-none-any.whl.metadata (4.0 kB)
#18 2.387 Collecting black==23.12.1 (from -r requirements.txt (line 44))
#18 2.396   Downloading black-23.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (68 kB)
#18 2.403      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 69.0/69.0 kB 16.5 MB/s eta 0:00:00
#18 2.442 Collecting flake8==7.0.0 (from -r requirements.txt (line 45))
#18 2.452   Downloading flake8-7.0.0-py2.py3-none-any.whl.metadata (3.8 kB)
#18 2.495 Collecting redis>=5.0.0 (from -r requirements.txt (line 50))
#18 2.504   Downloading redis-7.1.0-py3-none-any.whl.metadata (12 kB)
#18 2.518 ERROR: Could not find a version that satisfies the requirement langgraph-checkpoint-redis>=1.0.0 (from versions: 0.0.1, 0.0.2, 0.0.3, 0.0.4, 0.0.5, 0.0.6, 0.0.7, 0.0.8, 0.1.0, 0.1.1, 0.1.2, 0.1.3, 0.2.0, 0.2.1, 0.3.0, 0.3.1)
#18 2.519 ERROR: No matching distribution found for langgraph-checkpoint-redis>=1.0.0
#18 2.619 
#18 2.619 [notice] A new release of pip is available: 24.0 -> 25.3
#18 2.619 [notice] To update, run: pip install --upgrade pip
#18 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1

#37 [extraction_worker internal] load build context
#37 transferring context: 17.74MB 2.6s done
#37 CANCELED

#45 [frontend internal] load build context
#45 transferring context: 36.88MB 2.6s done
#45 CANCELED

#46 [api builder  5/12] RUN npm install --legacy-peer-deps
#46 CANCELED
------
 > [ai 5/6] RUN pip install --no-cache-dir -r requirements.txt:
2.403      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 69.0/69.0 kB 16.5 MB/s eta 0:00:00
2.442 Collecting flake8==7.0.0 (from -r requirements.txt (line 45))
2.452   Downloading flake8-7.0.0-py2.py3-none-any.whl.metadata (3.8 kB)
2.495 Collecting redis>=5.0.0 (from -r requirements.txt (line 50))
2.504   Downloading redis-7.1.0-py3-none-any.whl.metadata (12 kB)
2.518 ERROR: Could not find a version that satisfies the requirement langgraph-checkpoint-redis>=1.0.0 (from versions: 0.0.1, 0.0.2, 0.0.3, 0.0.4, 0.0.5, 0.0.6, 0.0.7, 0.0.8, 0.1.0, 0.1.1, 0.1.2, 0.1.3, 0.2.0, 0.2.1, 0.3.0, 0.3.1)
2.519 ERROR: No matching distribution found for langgraph-checkpoint-redis>=1.0.0
2.619 
2.619 [notice] A new release of pip is available: 24.0 -> 25.3
2.619 [notice] To update, run: pip install --upgrade pip
------
Dockerfile:18

--------------------

  16 |     

  17 |     # Install Python dependencies

  18 | >>> RUN pip install --no-cache-dir -r requirements.txt

  19 |     

  20 |     # Copy application code

--------------------

target ai: failed to solve: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1



View build details: docker-desktop://dashboard/build/default/default/pzocy62ty9ztkt3lv9yvn2zq6

